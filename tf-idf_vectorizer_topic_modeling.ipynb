{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to utilize TF-IDF vectorization in topic modeling, using the new_df dataframe built in final_dataframe_cleanup.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20,10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking in Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/cleaned_string_df.pickle','rb') as read_file:\n",
    "    new_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>string</th>\n",
       "      <th>line_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[good, evening, welcome, first, debate, among,...</td>\n",
       "      <td>good evening welcome first debate among major ...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[think, principal, separate, half, million, pe...</td>\n",
       "      <td>think principal separate half million people c...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[one, minute, response]</td>\n",
       "      <td>one minute response</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[important, distinction, campaign, represent, ...</td>\n",
       "      <td>important distinction campaign represent real ...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[one, minute, response, sir]</td>\n",
       "      <td>one minute response sir</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            stemmed  \\\n",
       "0      0  [good, evening, welcome, first, debate, among,...   \n",
       "1      1  [think, principal, separate, half, million, pe...   \n",
       "2      2                            [one, minute, response]   \n",
       "3      3  [important, distinction, campaign, represent, ...   \n",
       "4      4                       [one, minute, response, sir]   \n",
       "\n",
       "                                              string  line_length  \n",
       "0  good evening welcome first debate among major ...          100  \n",
       "1  think principal separate half million people c...           74  \n",
       "2                                one minute response            3  \n",
       "3  important distinction campaign represent real ...           45  \n",
       "4                            one minute response sir            4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next round of topic modeling, I will be using TF-IDF vectorizer, to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = ['presidential', 'vice', 'evening', 'debate', 'candidate', 'campaign', 'minute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, more stop words were implemented in final_dataframe_cleanup.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some responses can be very short (i.e. just a brief statement/quip), I am setting a minimum threshold of words for topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[new_df.line_length >= 40]['string']\n",
    "tfi_model = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_term_document_matrix = pd.DataFrame(tfi_model.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4439, 13077)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_term_document_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getthe the document set in terms of TF-IDF vectorization, below will try Topic Modelling using a few different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling via NMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics from the relating model, for each line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickbovard/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "/Users/patrickbovard/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4439, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_doc_topic = nmf_model.fit_transform(tf_term_document_matrix)\n",
    "tf_doc_topic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the top 10 words for each of the k topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "['nuclear', 'policy', 'believe', 'right', 'military', 'one', 'world', 'war', 'think', 'state', 'united', 'would']\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "['security', 'money', 'billion', 'budget', 'rate', 'social', 'pay', 'plan', 'income', 'percent', 'cut', 'tax']\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "['drug', 'universal', 'affordable', 'company', 'system', 'people', 'cost', 'medicare', 'plan', 'insurance', 'care', 'health']\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "['family', 'every', 'student', 'need', 'college', 'public', 'parent', 'kid', 'teacher', 'child', 'education', 'school']\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "['economy', 'know', 'america', 'need', 'work', 'got', 'think', 'make', 'get', 'job', 'people', 'going']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_words = vectorizer.get_feature_names()\n",
    "tf = nmf_model.components_.argsort(axis=1)[:,-12:]\n",
    "tf_topic_words = [[tf_words[e] for e in l] for l in tf]\n",
    "for i, words in enumerate(tf_topic_words, 1):\n",
    "    print('Topic {}:'.format(i))\n",
    "    print(words)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, the 6 topics seem to be about the following: \n",
    "1. Random Bucket\n",
    "2. Economy/Taxes\n",
    "3. Healthcare (clear)\n",
    "4. War/Foreign Policy\n",
    "5. Education\n",
    "6. Random Bucket, with hints of jobs/campaign \"speak\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the document-topic matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04950632, 0.        , 0.00210316, 0.00154697, 0.00233575],\n",
       "       [0.0047256 , 0.00114881, 0.00267339, 0.        , 0.09788421],\n",
       "       [0.00831018, 0.02411788, 0.        , 0.        , 0.05872428],\n",
       "       ...,\n",
       "       [0.00496225, 0.00373031, 0.01367251, 0.        , 0.06744766],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.08555705],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.08605519]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling via LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LDA(n_components = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4439, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_doc_topic = lda_model.fit_transform(tf_term_document_matrix)\n",
    "lda_doc_topic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the top 10 words for each of the k topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "['hussein', 'isi', 'north', 'china', 'saddam', 'ally', 'korea', 'israel', 'syria', 'weapon', 'iran', 'nuclear']\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "['time', 'right', 'need', 'know', 'make', 'one', 'get', 'tax', 'would', 'think', 'going', 'people']\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "['april', 'cardiologist', 'mar', 'klan', 'floyd', 'paso', 'conversion', 'shame', 'filter', 'yugoslavia', 'gramm', 'depletion']\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "['xx', 'invention', 'freddie', 'clip', 'suburb', 'mac', 'humble', 'shooting', 'occurs', 'investigation', 'uphold', 'contra']\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "['la', 'contain', 'matsu', 'flight', 'quemoy', 'lesbian', 'columbine', 'trigger', 'formosa', 'shooting', 'island', 'handgun']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_words = vectorizer.get_feature_names()\n",
    "tf = lda_model.components_.argsort(axis=1)[:,-12:]\n",
    "tf_topic_words = [[tf_words[e] for e in l] for l in tf]\n",
    "for i, words in enumerate(tf_topic_words, 1):\n",
    "    print('Topic {}:'.format(i))\n",
    "    print(words)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics definitely make less sense as of now compared to NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling via LSA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LSA, using TruncatedSVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00291337, 0.00773775, 0.00568375, 0.00461262, 0.00402213])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(5)\n",
    "doc_topic = lsa.fit_transform(tf_term_document_matrix)\n",
    "lsa.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the top 10 words for each of the k topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "['america', 'job', 'know', 'need', 'make', 'one', 'get', 'would', 'think', 'going', 'tax', 'people']\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "['business', 'billion', 'budget', 'money', 'social', 'rate', 'pay', 'plan', 'income', 'percent', 'cut', 'tax']\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "['affordable', 'education', 'people', 'system', 'cost', 'school', 'plan', 'medicare', 'child', 'insurance', 'care', 'health']\n",
      "\n",
      "\n",
      "Topic 4:\n",
      "['life', 'gun', 'family', 'student', 'public', 'parent', 'college', 'kid', 'teacher', 'child', 'education', 'school']\n",
      "\n",
      "\n",
      "Topic 5:\n",
      "['teacher', 'education', 'medicare', 'federal', 'child', 'think', 'cut', 'program', 'school', 'security', 'social', 'would']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_words = vectorizer.get_feature_names()\n",
    "tf = lsa.components_.argsort(axis=1)[:,-12:]\n",
    "tf_topic_words = [[tf_words[e] for e in l] for l in tf]\n",
    "for i, words in enumerate(tf_topic_words, 1):\n",
    "    print('Topic {}:'.format(i))\n",
    "    print(words)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
